# -*- coding: utf-8 -*-
"""Recommendation System_Behaviors_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kZ5YOb3zH5stuqcw6AafGLZ-6ywtQpAT

# Import Libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from imblearn.over_sampling import SMOTE
from sklearn.utils.class_weight import compute_class_weight
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.decomposition import PCA
from xgboost import XGBClassifier
from imblearn.pipeline import Pipeline as ImbPipeline
import xgboost as xgb

from xgboost import DMatrix
from sklearn.model_selection import  StratifiedKFold

from sklearn.calibration import CalibratedClassifierCV
from sklearn.metrics import (classification_report, confusion_matrix, roc_curve, auc, accuracy_score, precision_score, recall_score, f1_score, mean_squared_error, mean_absolute_error )
from sklearn.preprocessing import label_binarize

!pip install flask-ngrok
!pip install pyngrok

import joblib
from flask import Flask, request, render_template_string
from flask_ngrok import run_with_ngrok
from pyngrok import ngrok
from datetime import datetime

"""# Load the Dataset"""

data = pd.read_csv('Corrupted_Merged_Student_Dataset.csv')

"""# Data Preprocessing Stage 1"""

data.tail()

print(data.isnull().sum())

# Handle Missing Values
data.fillna(data.median(numeric_only=True), inplace=True)

print(data.isnull().sum())

print(data.duplicated().sum())

data.describe()

data.columns

data.info()

data.columns = data.columns.str.strip()
for col in data.select_dtypes(include=["object"]).columns:
    data[col] = data[col].replace(r'\s+', ' ', regex=True)

data.columns

numeric_cols = data.select_dtypes(include=['float64', 'int64']).columns
plt.figure(figsize=(18, 8))
data[numeric_cols].boxplot(rot=45)
plt.title("Boxplot to detect outliers")
plt.show()

# IQR
def detect_outliers_IQR(df):
    outlier_columns = []
    for col in df.select_dtypes(include=["float64", "int64"]).columns:
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        lower = Q1 - 1.5 * IQR
        upper = Q3 + 1.5 * IQR
        outliers = df[(df[col] < lower) | (df[col] > upper)]
        if not outliers.empty:
            print(f"{col}: {len(outliers)} outliers")
            outlier_columns.append(col)
    print("\nColumns with outliers:", outlier_columns)
    return outlier_columns
outlier_columns = detect_outliers_IQR(data)

# Function to cap outliers
def cap_outliers(df, column):
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    df[column] = np.clip(df[column], lower_bound, upper_bound)
# Detect and handle outliers
outlier_columns = detect_outliers_IQR(data)
for col in outlier_columns:
    cap_outliers(data, col)
# Plot the results
plt.figure(figsize=(15, 6))
sns.boxplot(data=data[outlier_columns])
plt.xticks(rotation=45)
plt.title("After Handling the Outliers", fontsize=14)
plt.tight_layout()
plt.show()
# Display the columns with outliers
outlier_columns

numeric_cols = data.select_dtypes(include=['float64', 'int64']).columns
plt.figure(figsize=(18, 8))
data[numeric_cols].boxplot(rot=45)
plt.title("Boxplot to detect outliers")
plt.show()

# Converting Date Columns
data['Enrollment_Date'] = pd.to_datetime(data['Enrollment_Date'], errors='coerce')

# Feature Engineering
data['enrollment_year'] = data['Enrollment_Date'].dt.year
data['enrollment_month'] = data['Enrollment_Date'].dt.month
data['enrollment_day'] = data['Enrollment_Date'].dt.day

# Create new features based on existing columns
data['study_hours_per_week_to_age_ratio'] = data['Study_Hours_per_Week'] / data['Age']
data['participation_rate'] = data['Participation_in_Discussions'].map({'Yes': 1, 'No': 0}) * 100
data['exam_attendance_rate'] = (data['Exam_Score (%)'] + data['Attendance_Rate (%)']) / 2
data['study_hours_to_exam_score'] = data['Study_Hours_per_Week'] / data['Exam_Score (%)']
data['study_hours_to_attendance'] = data['Study_Hours_per_Week'] / data['Attendance_Rate (%)']
data['tech_use_to_exam_score'] = data['Use_of_Educational_Tech'].map({'Yes': 1, 'No': 0}) * data['Exam_Score (%)']
data['social_media_time_to_exam'] = data['Time_Spent_on_Social_Media (hours/week)'] / data['Exam_Score (%)']
data['weighted_exam_score'] = (data['Exam_Score (%)'] * 0.4) + (data['Attendance_Rate (%)'] * 0.3) + (data['Study_Hours_per_Week'] * 0.3)
data['learning_style_effect'] = data.groupby('Preferred_Learning_Style')['Exam_Score (%)'].transform('mean')

missing_values = data.isna().sum()
print(missing_values)

data.head()

data.tail()

# Plotting each Numerical_feature_Distribution
Numeric_data = data[['Age', 'Study_Hours_per_Week', 'Online_Courses_Completed',
                     'Assignment_Completion_Rate (%)', 'Exam_Score (%)', 'Attendance_Rate (%)',
                     'Time_Spent_on_Social_Media (hours/week)', 'Sleep_Hours_per_Night',
                     'Final_Grade', 'Self_Reported_Stress_Level', 'study_hours_per_week_to_age_ratio',
                     'participation_rate', 'exam_attendance_rate', 'study_hours_to_exam_score',
                     'study_hours_to_attendance', 'tech_use_to_exam_score', 'social_media_time_to_exam',
                     'weighted_exam_score', 'learning_style_effect']]

for col in Numeric_data:
    plt.figure(figsize=(15, 4))
    sns.histplot(data[col], kde=True, color="skyblue", bins=20)
    plt.title(f"{col} Distribution")
    plt.xlabel(col)
    plt.ylabel("Count")
    plt.show()

# Plotting each Categorial_feature_Distribution
Categorical_data = data[['Gender', 'Preferred_Learning_Style', 'Online_Courses_Completed',
                         'Participation_in_Discussions', 'Preferred_Learning_Strategy',
                         'Hearing_Issue', 'Vision_Issue', 'Focus_Issue',
                         'Language_Proficiency']]
for col in Categorical_data:
    plt.figure(figsize=(20, 5))
    sns.countplot(x=data[col], palette="Blues")
    plt.title(f"{col} Distribution")
    plt.xlabel(col)
    plt.ylabel("Count")
    plt.show()

# Plotting Distribution of Study Hours per Week
plt.figure(figsize=(10, 5))
sns.histplot(data['Study_Hours_per_Week'], bins=30, kde=True)
plt.title('Distribution of Study Hours per Week')
plt.xlabel('Study Hours per Week')
plt.ylabel('Frequency')
plt.show()

# Plotting Distribution of Age
plt.figure(figsize=(10, 5))
sns.histplot(data['Age'], bins=30, kde=True)
plt.title('Distribution of Age')
plt.xlabel('Age')
plt.ylabel('Frequency')
plt.show()

# Plotting Distribution of  Final Grade
plt.figure(figsize=(10, 5))
sns.histplot(data['Final_Grade'], bins=30, kde=True)
plt.title('Distribution of Final Grade')
plt.xlabel('Final Grade')
plt.ylabel('Frequency')
plt.show()

# Plotting Preferred Learning Style vs Final Grade
plt.figure(figsize=(20, 5))
sns.boxplot(data=data, x="Preferred_Learning_Style", y="Final_Grade", palette="Blues")
plt.title("Preferred Learning Style vs Final Grade")
plt.xlabel("Preferred Learning Style")
plt.ylabel("Final Grade")
plt.show()

# Plotting Study Hours per Week vs Exam Score
plt.figure(figsize=(20, 10))
sns.scatterplot(data=data, x="Study_Hours_per_Week", y="Exam_Score (%)", hue="Gender")
plt.title("Study Hours per Week vs Exam Score")
plt.xlabel("Study Hours per Week")
plt.ylabel("Exam Score (%)")
plt.legend(title="Gender")
plt.show()

# Plotting Age vs Participation in Discussions
plt.figure(figsize=(20, 5))
sns.countplot(data=data, x="Age", hue="Participation_in_Discussions", palette="Blues")
plt.title("Age vs Participation in Discussions")
plt.xlabel("Age")
plt.ylabel("Count")
plt.legend(title="Participation in Discussions")
plt.show()

# Plotting Study Hours per Week vs Assignment Completion Rate (%)
plt.figure(figsize=(20, 10))
sns.regplot(data=data, x="Study_Hours_per_Week", y="Assignment_Completion_Rate (%)", scatter_kws={"color": "blue"}, line_kws={"color": "red"})
plt.title("Study Hours per Week vs Assignment Completion Rate (%)")
plt.xlabel("Study Hours per Week")
plt.ylabel("Assignment Completion Rate (%)")
plt.show()

# Plotting Online Courses Completed vs Exam Score
plt.figure(figsize=(20, 5))
sns.barplot(data=data, x="Online_Courses_Completed", y="Exam_Score (%)")
plt.title("Online Courses Completed vs Exam Score")
plt.xlabel("Online Courses Completed")
plt.ylabel("Exam Score (%)")
plt.show()

## Plotting Correlation Heatmap
numeric_data = data.select_dtypes(include=['float64', 'int64'])
correlation_matrix = numeric_data.corr()
plt.figure(figsize=(20, 10))
sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm", fmt=".2f", linewidths=0.5)
plt.title("Correlation Heatmap")
plt.show()

"""# **Data Preprocessing Stage 2**"""

# Label Encoding for categorial data
categorical_cols = ["Gender", "Preferred_Learning_Style",
                    "Participation_in_Discussions","Use_of_Educational_Tech","Self_Reported_Stress_Level", "Preferred_Learning_Strategy",
                    "Hearing_Issue","Final_Grade", "Vision_Issue", "Focus_Issue", "Language_Proficiency"]
label_encoders = {}
for col in categorical_cols:
    le = LabelEncoder()
    data[col] = le.fit_transform(data[col].astype(str))
    label_encoders[col] = le
print(data[categorical_cols].head())

#Removing (Drop) unwanted columns
data = data.drop(["participation_rate", "tech_use_to_exam_score", "social_media_time_to_exam","User_ID","Unnamed: 0","Student_ID","User_ID" ], axis=1)

#Show the result of drop columns
missing_values = data.isna().sum()
print(missing_values)

data.head()

# Scaling and normalizing data
numeric_cols = ['Age', 'Study_Hours_per_Week', 'Assignment_Completion_Rate (%)', 'Exam_Score (%)', 'Attendance_Rate (%)',
                'study_hours_per_week_to_age_ratio', 'exam_attendance_rate', 'study_hours_to_exam_score', 'study_hours_to_attendance', 'weighted_exam_score', 'learning_style_effect']

X_numeric = data[numeric_cols]
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_numeric)
X_scaled_df = pd.DataFrame(X_scaled, columns=numeric_cols)
X_final = pd.concat([X_scaled_df, data.drop(columns=numeric_cols)], axis=1)
print(X_final.head())

data.to_csv('Preprocessed_Student_Dataset.csv', index=False)

# balancing data
# Load your preprocessed dataset
data = pd.read_csv('Preprocessed_Student_Dataset.csv')

# Check current distribution
print(data['Preferred_Learning_Strategy'].value_counts())

# Find the minimum class count
min_count = data['Preferred_Learning_Strategy'].value_counts().min()

# Balance dataset
data = (
    data.groupby('Preferred_Learning_Strategy')
        .apply(lambda x: x.sample(min_count, random_state=42))
        .reset_index(drop=True)
)

# Verify new distribution
print(data['Preferred_Learning_Strategy'].value_counts())

# Save the balanced dataset
data.to_csv('Balanced_Preprocessed_Dataset.csv', index=False)

# Drop the target column from features
X = data.drop(columns=['Preferred_Learning_Strategy'])

# Define target column
y = data['Preferred_Learning_Strategy']

# Scaling the features (Apply scaling to X after dropping the target)
numeric_cols = ['Age', 'Study_Hours_per_Week', 'Assignment_Completion_Rate (%)', 'Exam_Score (%)', 'Attendance_Rate (%)',
                'study_hours_per_week_to_age_ratio', 'exam_attendance_rate', 'study_hours_to_exam_score', 'study_hours_to_attendance', 'weighted_exam_score', 'learning_style_effect'] # Make sure these columns exist in your X

# Select only the numeric columns from X for scaling
X_numeric = X[numeric_cols]

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_numeric)

# Create a DataFrame from scaled numeric features and keep other columns from X
X_scaled_df = pd.DataFrame(X_scaled, columns=numeric_cols, index=X.index) # Use original index to merge
X_final = pd.concat([X_scaled_df, X.drop(columns=numeric_cols)], axis=1)

print(X_final.head())

#Apply PCA (for Dimensionality Reduction)
pca = PCA(n_components=X_scaled.shape[1])
X_pca = pca.fit_transform(X_scaled)

n_components = np.argmax(np.cumsum(pca.explained_variance_ratio_) >= 0.95) + 1
X_pca_reduced = X_pca[:, :n_components]
X_pca_df = pd.DataFrame(X_pca_reduced, columns=[f"PCA_{i+1}" for i in range(n_components)])
print(X_pca_df.head())

# cumulative_variance Calculation
explained_variance_ratio = pca.explained_variance_ratio_
cumulative_variance = np.cumsum(explained_variance_ratio)

# Plotting Scree Plot
plt.figure(figsize=(10, 6))
plt.plot(range(1, len(explained_variance_ratio) + 1), cumulative_variance, marker='o', linestyle='--', color='b')
plt.axhline(y=0.95, color='r', linestyle='-')
plt.title('Scree Plot - Explained Variance by PCA Components')
plt.xlabel('Number of Principal Components')
plt.ylabel('Cumulative Explained Variance')
plt.grid(True)
plt.show()

# Handle Imbalanced Data using SMOTE
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_pca_df, y)

print("Original shape:", X_pca_df.shape, y.shape)
print("Resampled shape:", X_resampled.shape, y_resampled.shape)

## Plotting Correlation Heatmap
numeric_data = data.select_dtypes(include=['float64', 'int64'])
correlation_matrix = numeric_data.corr()
plt.figure(figsize=(20, 10))
target = 'preffered_Learning_Strategy'
sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm", fmt=".2f", linewidths=0.5)
plt.title("Correlation Heatmap")
plt.show()

print(f"Features: {X}")  # Inspect the features before passing to model

!pip install xgboost

!pip install --upgrade xgboost

import xgboost
print(xgboost.__version__)

# 1. Drop or process datetime columns
if 'Enrollment_Date' in X.columns:
    X = X.drop(columns=['Enrollment_Date'])

# 3. Define custom feature weights (importance multipliers)
feature_weights = {
    # Demographics
    'Age': 1.0,
    'Gender': 1.0,

    # Academic Metrics
    'Study_Hours_per_Week': 1.0,
    'Online_Courses_Completed': 1.0,
    'Participation_in_Discussions': 1.0,
    'Assignment_Completion_Rate (%)': 1.0,
    'Exam_Score (%)': 1.0,
    'Attendance_Rate (%)': 1.0,
    'Final_Grade': 1.0,
    # Learning Factors
    'Preferred_Learning_Style': 1.0,
    'Use_of_Educational_Tech': 1.0,
    'Language_Proficiency': 1.0,

    # Well-being Metrics
    'Self_Reported_Stress_Level': 1.0,
    'Time_Spent_on_Social_Media (hours/week)': 1.0,
    'Sleep_Hours_per_Night': 1.0,

    # Health Factors
    'Hearing_Issue': 1.0,
    'Vision_Issue': 1.0,
    'Focus_Issue': 1.0,



    # Derived Features
    'enrollment_year': 1.0,
    'enrollment_month': 1.0,
    'enrollment_day': 1.0,
    'study_hours_per_week_to_age_ratio': 1.0,
    'exam_attendance_rate': 1.0,
    'study_hours_to_exam_score': 1.0,
    'study_hours_to_attendance': 1.0,
    'weighted_exam_score': 1.0,
    'learning_style_effect': 1.0
}
# 4. Apply weights to features
for feature, weight in feature_weights.items():
    if feature in X.columns:
        X[feature] = X[feature] * weight

#  print weighted features for verification
print("\nFeature Weighting Applied:")
for feature, weight in feature_weights.items():
    if weight != 1.0 and feature in X.columns:
        print(f"{feature}: x{weight}")

# 5. Split data with stratification
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, stratify=y, random_state=42
)
# 6. Define XGBoost parameters
params = {
    'objective': 'multi:softprob',
    'num_class': 3,
    'max_depth': 6,
    'learning_rate': 0.02,
    'subsample': 0.9,
    'colsample_bytree': 0.5,
    'reg_alpha': 1.0,
    'reg_lambda': 5.0,
    'eval_metric': ['mlogloss', 'merror'],
    'seed': 42
}

# 7. Train with early stopping
dtrain = DMatrix(X_train, label=y_train)
dtest = DMatrix(X_test, label=y_test)

evals_result = {}
xgb_model = xgb.train(
    params,
    dtrain,
    num_boost_round=20,
    evals=[(dtrain, 'train'), (dtest, 'eval')],
    early_stopping_rounds=19,
    evals_result=evals_result,

    verbose_eval=1
)

best_iteration = xgb_model.best_iteration
print(f"\nBest iteration: {best_iteration}")



skf = StratifiedKFold(n_splits=3)
cv_results = xgb.cv(
    params=params,

    dtrain=dtrain,
    num_boost_round=20,
    folds=skf,
    metrics='mlogloss',
    early_stopping_rounds=20,
    verbose_eval=1,
    show_stdv=True,
    seed=42,
    as_pandas=True,
    maximize=False,
    nfold=5,
    shuffle=True,
    stratified=True


)
print(cv_results)

le = LabelEncoder()
y_encoded = le.fit_transform(y)

print(f"y_encoded sample: {y_encoded[100:2000]}")
print(f"y_encoded type: {type(y_encoded)}")
print(f"y_encoded element type: {type(y_encoded[0])}")

# 8. Evaluate on test set
y_proba = xgb_model.predict(dtest)
y_pred = y_proba.argmax(axis=1)

test_metrics = {
    'Accuracy': accuracy_score(y_test, y_pred),
    'Precision': precision_score(y_test, y_pred, average='weighted'),
    'Recall': recall_score(y_test, y_pred, average='weighted'),
    'F1': f1_score(y_test, y_pred, average='weighted')
}
print("\nTest Set Metrics:")
print(classification_report(y_test, y_pred))

for metric, value in test_metrics.items():
    print(f"{metric}: {value:.4f}")

print("\n")
# 9. Plot training vs validation error
plt.figure(figsize=(10, 6))
plt.plot(evals_result['train']['merror'], label='Train Error', linestyle='--')
plt.plot(evals_result['eval']['merror'], label='Validation Error')
plt.xlabel('Boosting Round')
plt.ylabel('Error Rate')
plt.title('Training vs Validation Error')
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(12, 6))

# Extract 'merror' from evals_result and calculate accuracy
train_error = evals_result['train']['merror']
eval_error = evals_result['eval']['merror']
train_acc = [1 - error for error in train_error]
eval_acc = [1 - error for error in eval_error]
# Plot accuracy
plt.subplot(1, 2, 1)
plt.plot(train_acc, label='Train Accuracy', color='blue', marker='o', markersize=3)
plt.plot(eval_acc, label='Validation Accuracy', color='red', marker='o', markersize=3)
plt.xlabel('Boosting Round')
plt.ylabel('Accuracy')
plt.title('Train vs Validation Accuracy')
plt.legend()
plt.grid(True)

# Plot accuracy gap (Train - Validation)
plt.subplot(1, 2, 2)
accuracy_gap = np.array(train_acc) - np.array(eval_acc)
plt.plot(accuracy_gap, label='Accuracy Gap (Train - Val)', color='purple', linestyle='--')
plt.axhline(y=0, color='gray', linestyle='-', linewidth=0.5)
plt.xlabel('Boosting Round')
plt.ylabel('Accuracy Gap')
plt.title('Overfitting Indicator: Accuracy Gap')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.show()

# 1. Get raw feature importance scores (gain)
feature_importances = xgb_model.get_score(importance_type='gain')

# 2. Mapping to actual column names
feature_map = {f"f{i}": col for i, col in enumerate(X.columns)}

# 3. Create DataFrame with real feature names and importance values
importance_values = pd.DataFrame({
    'Feature': [feature_map.get(k, k) for k in feature_importances.keys()],
    'Importance': list(feature_importances.values())
})

# 4. Normalize to get percentage
total_gain = importance_values['Importance'].sum()
importance_values['Importance (%)'] = (importance_values['Importance'] / total_gain) * 100

# 5. Sort by importance descending
importance_values = importance_values.sort_values(by='Importance', ascending=False).reset_index(drop=True)

# 6. Print with percentage
print(importance_values)

# 7. Plot feature importances with percentage

plt.figure(figsize=(12, 8))
plt.barh(importance_values['Feature'], importance_values['Importance (%)'])
plt.xlabel('Gain Importance (%)')
plt.title('XGBoost Feature Importances (by Gain %)')
plt.gca().invert_yaxis()
plt.tight_layout()
plt.show()

# Normalize importance scores to percentage
importance_values['Percentage'] = (importance_values['Importance'] / importance_values['Importance'].sum()) * 100

# Sort if not already
importance_values = importance_values.sort_values(by='Percentage', ascending=False)

plt.figure(figsize=(14, 8))
bars = plt.barh(importance_values['Feature'], importance_values['Percentage'], color='skyblue')

plt.xlabel('Gain-Based Importance (%)', fontsize=14)
plt.title('Feature Importance (Gain) - XGBoost', fontsize=16)
plt.xticks(fontsize=12)
plt.yticks(fontsize=12)

plt.gca().invert_yaxis()
plt.grid(True, axis='x', linestyle='--', alpha=0.7)

# Add percentage labels to bars
for bar in bars:
    width = bar.get_width()
    plt.text(width + 0.5, bar.get_y() + bar.get_height() / 2,
             f'{width:.1f}%', va='center', fontsize=10)

plt.tight_layout()
plt.show()

print(f"Target: {y}")  # target

# =============================
# Predict Labels and Probabilities
# =============================
# Convert X_test to DMatrix for prediction
dtest = xgb.DMatrix(X_test)

# Get probability predictions
y_pred_proba = xgb_model.predict(dtest)  # shape: (n_samples, n_classes)

# Get predicted classes (highest probability)
y_pred = np.argmax(y_pred_proba, axis=1)

# =============================
# 1. Classification Metrics
# =============================
print("\n" + "="*50)
print("Classification Performance Metrics")
print("="*50)

accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
f1 = f1_score(y_test, y_pred, average='weighted')

print(f"\nAccuracy: {accuracy:.4f}")
print(f"Precision (Weighted): {precision:.4f}")
print(f"Recall (Weighted): {recall:.4f}")
print(f"F1-Score (Weighted): {f1:.4f}")

print("\nClassification Report:")
print(classification_report(y_test, y_pred))
# =============================
# 2. Regression-style Metrics
# =============================
print("\n" + "="*50)
print("Regression-style Metrics (Treating Classes as Ordinal)")
print("="*50)

rmse = np.sqrt(mean_squared_error(y_test, y_pred))
mae = mean_absolute_error(y_test, y_pred)

print(f"\nRMSE: {rmse:.4f}")
print(f"MAE: {mae:.4f}")

# =============================
# 3. Confusion Matrix
# =============================
plt.figure(figsize=(10, 6))
cm = confusion_matrix(y_test, y_pred)

# Get class labels if LabelEncoder was used
try:
    class_labels = le.inverse_transform(np.unique(y_test))
except:
    class_labels = np.unique(y_test)

sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=class_labels,
            yticklabels=class_labels)

plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.tight_layout()
plt.show()

# =============================
# 4. ROC Curve (Multiclass)
# =============================
y_test_bin = label_binarize(y_test, classes=np.unique(y_test))  # binarize actual labels
n_classes = y_test_bin.shape[1]

fpr = dict()
tpr = dict()
roc_auc = dict()

for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_pred_proba[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

plt.figure(figsize=(12, 8))
for i in range(n_classes):
    label = f"Class {le.inverse_transform([i])[0]}" if 'le' in locals() else f"Class {i}"
    plt.plot(fpr[i], tpr[i], label=f'{label} (AUC = {roc_auc[i]:.2f})')

plt.plot([0, 1], [0, 1], 'k--', lw=1)
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Multiclass ROC Curve')
plt.legend(loc="lower right")
plt.tight_layout()
plt.show()

# Simulate label encoding if your model expects encoded targets
label_encoder = LabelEncoder().fit(y_train)
y_train_encoded = label_encoder.transform(y_train)

# Create XGBClassifier and load trained booster
xgb_clf = XGBClassifier()
xgb_clf._Booster = xgb_model
xgb_clf.n_classes_ = 3  # Adjust based on your actual problem
xgb_clf._le = label_encoder  # Attach the label encoder

# Optional: set classifier params if needed for inference
xgb_clf._feature_names = X_train.columns.tolist()

# Wrap it in a pipeline (no preprocessing steps in this case)
pipeline = Pipeline([
    ('classifier', xgb_clf)
])

# Save the pipeline and feature names
features_used_for_training = X_train.columns.tolist()
joblib.dump((pipeline, features_used_for_training), 'learning_strategy_pipeline.pkl')

print("‚úÖ Pipeline and feature names saved successfully.")
print("Features used:", features_used_for_training)

xgb_model.save_model("xgb_model.json")  # or "xgb_model.model"

# Original class distribution counts
print("Original class distribution counts:")
print(y.value_counts())

# Plot original class distribution
y.value_counts().plot(kind='bar')
plt.title("Target Class Distribution")
plt.xlabel("Class")
plt.ylabel("Count")
plt.show()

# Predicted class distribution counts
print("Predicted class distribution counts:")
print(pd.Series(y_pred).value_counts())

# Plot predicted class distribution
pd.Series(y_pred).value_counts().plot(kind='bar')
plt.title("Predicted Class Distribution")
plt.xlabel("Class")
plt.ylabel("Count")
plt.show()

# Create DMatrix from the test set
dtest = xgb.DMatrix(X_test)

# Get probability predictions from the model
# Use the correct model variable name: xgb_model
y_pred_proba = xgb_model.predict(dtest)
# Convert probability predictions to class labels by taking the index of the maximum probability
y_pred_labels = np.argmax(y_pred_proba, axis=1)

# Now pass the true labels (y_test) and the predicted labels (y_pred_labels) to classification_report
print(classification_report(y_test, y_pred_labels))

# Correct import and token order
ngrok.set_auth_token("")

# Load the model
calibrated_model = joblib.load('learning_strategy_pipeline.pkl')
# Define the features that are derived (calculated)
derived_features = [
    'study_hours_per_week_to_age_ratio',
    'exam_attendance_rate',
    'study_hours_to_exam_score',
    'study_hours_to_attendance',
    'weighted_exam_score',
    'learning_style_effect'
]
# Load the model and feature list
pipeline, features_used_for_training = joblib.load('learning_strategy_pipeline.pkl')
calibrated_model = pipeline  # or rename if you prefer

# Use the correct variable name 'features_used_for_training'
base_features = [f for f in features_used_for_training if f not in derived_features]
html = """
<!DOCTYPE html>
<html lang="en" class="dark">
<head>
    <meta charset="UTF-8">
    <title>Learning Strategy Predictor</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script>
        tailwind.config = { darkMode: 'class' };
    </script>
    <style>
        @keyframes fade-in {
            from { opacity: 0; transform: translateY(10px); }
            to { opacity: 1; transform: translateY(0); }
        }

        .animate-fade-in {
            animation: fade-in 0.6s ease-out;
        }
    </style>
    <script>
        function setEnrollmentDateFields() {
            const enrollmentDate = document.getElementById("enrollment_date").value;
            const [year, month, day] = enrollmentDate.split("-");
            document.getElementById("enrollment_year").value = year;
            document.getElementById("enrollment_month").value = month;
            document.getElementById("enrollment_day").value = day;
        }
    </script>
</head>
<body class="bg-gradient-to-br from-gray-100 to-gray-300 dark:from-gray-900 dark:to-gray-800 text-gray-800 dark:text-white min-h-screen flex items-center justify-center p-6">
    <div class="bg-white dark:bg-gray-900 shadow-2xl rounded-3xl p-10 w-full max-w-5xl space-y-6 animate-fade-in transition-all duration-300">
        <h2 class="text-4xl font-bold text-center text-indigo-600 dark:text-indigo-400">üéì Learning Strategy Predictor</h2>
        <form method="POST" action="/predict" onsubmit="setEnrollmentDateFields()" class="grid grid-cols-1 md:grid-cols-2 gap-6">

            <!-- Inputs start -->
            <div>
                <label class="block text-gray-700 dark:text-gray-300">Age:</label>
                <input type="number" name="age" required min="1" class="w-full p-3 border rounded-xl dark:bg-gray-800 dark:border-gray-600">
            </div>

            <div>
                <label class="block text-gray-700 dark:text-gray-300">Gender:</label>
                <select name="gender" required class="w-full p-3 border rounded-xl dark:bg-gray-800 dark:border-gray-600">
                    <option value="">Select gender</option>
                    <option>Male</option>
                    <option>Female</option>
                </select>
            </div>

            <div>
                <label class="block text-gray-700 dark:text-gray-300">Study Hours/Week:</label>
                <input type="number" name="study_hours" required min="1" class="w-full p-3 border rounded-xl dark:bg-gray-800 dark:border-gray-600">
            </div>

            <div>
                <label class="block text-gray-700 dark:text-gray-300">Learning Style:</label>
                <select name="learning_style" required class="w-full p-3 border rounded-xl dark:bg-gray-800 dark:border-gray-600">
                    <option>Visual</option>
                    <option>Auditory</option>
                    <option>Kinesthetic</option>
                    <option>Reading/Writing</option>
                </select>
            </div>

            <div>
                <label class="block text-gray-700 dark:text-gray-300">Online Courses Completed:</label>
                <input type="number" name="online_courses" required min="0" class="w-full p-3 border rounded-xl dark:bg-gray-800 dark:border-gray-600">
            </div>

            <div>
                <label class="block text-gray-700 dark:text-gray-300">Participation:</label>
                <select name="participation" required class="w-full p-3 border rounded-xl dark:bg-gray-800 dark:border-gray-600">
                    <option>YES</option>
                    <option>NO</option>
                </select>
            </div>

            <div>
                <label class="block text-gray-700 dark:text-gray-300">Assignment Completion Rate (%):</label>
                <input type="number" name="assignment_rate" required min="0" max="100" class="w-full p-3 border rounded-xl dark:bg-gray-800 dark:border-gray-600">
            </div>

            <div>
                <label class="block text-gray-700 dark:text-gray-300">Exam Score (%):</label>
                <input type="number" name="exam_score" required min="0" max="100" class="w-full p-3 border rounded-xl dark:bg-gray-800 dark:border-gray-600">
            </div>

            <div>
                <label class="block text-gray-700 dark:text-gray-300">Attendance Rate (%):</label>
                <input type="number" name="attendance" required min="0" max="100" class="w-full p-3 border rounded-xl dark:bg-gray-800 dark:border-gray-600">
            </div>

            <div>
                <label class="block text-gray-700 dark:text-gray-300">Technology Use:</label>
                <select name="tech_use" required class="w-full p-3 border rounded-xl dark:bg-gray-800 dark:border-gray-600">
                    <option>Low</option>
                    <option>Medium</option>
                    <option>High</option>
                </select>
            </div>

            <div>
                <label class="block text-gray-700 dark:text-gray-300">Stress Level:</label>
                <select name="stress_level" required class="w-full p-3 border rounded-xl dark:bg-gray-800 dark:border-gray-600">
                    <option>Low</option>
                    <option>Medium</option>
                    <option>High</option>
                </select>
            </div>

            <div>
                <label class="block text-gray-700 dark:text-gray-300">Social Media (hours/week):</label>
                <input type="number" name="social_media" required min="0" class="w-full p-3 border rounded-xl dark:bg-gray-800 dark:border-gray-600">
            </div>

            <div>
                <label class="block text-gray-700 dark:text-gray-300">Sleep Hours per Night:</label>
                <input type="number" name="sleep_hours" required min="0" class="w-full p-3 border rounded-xl dark:bg-gray-800 dark:border-gray-600">
            </div>

            <div>
                <label class="block text-gray-700 dark:text-gray-300">Final Grade (A-F):</label>
                <select name="final_grade" required class="w-full p-3 border rounded-xl dark:bg-gray-800 dark:border-gray-600">
                    <option>A</option>
                    <option>B</option>
                    <option>C</option>
                    <option>D</option>
                    <option>F</option>
                </select>
            </div>

            <div>
                <label class="block text-gray-700 dark:text-gray-300">Hearing Issue:</label>
                <select name="hearing_issue" required class="w-full p-3 border rounded-xl dark:bg-gray-800 dark:border-gray-600">
                    <option>YES</option>
                    <option>NO</option>
                </select>
            </div>

            <div>
                <label class="block text-gray-700 dark:text-gray-300">Vision Issue:</label>
                <select name="vision_issue" required class="w-full p-3 border rounded-xl dark:bg-gray-800 dark:border-gray-600">
                    <option>YES</option>
                    <option>NO</option>
                </select>
            </div>

            <div>
                <label class="block text-gray-700 dark:text-gray-300">Focus Issue:</label>
                <select name="focus_issue" required class="w-full p-3 border rounded-xl dark:bg-gray-800 dark:border-gray-600">
                    <option>YES</option>
                    <option>NO</option>
                </select>
            </div>

            <div>
                <label class="block text-gray-700 dark:text-gray-300">Language Proficiency (0-1):</label>
                <input type="number" step="0.01" name="language_proficiency" required min="0" max="1" class="w-full p-3 border rounded-xl dark:bg-gray-800 dark:border-gray-600">
            </div>

            <div class="col-span-2">
                <label class="block text-gray-700 dark:text-gray-300">Enrollment Date:</label>
                <input type="date" name="enrollment_date" id="enrollment_date" required class="w-full p-3 border rounded-xl dark:bg-gray-800 dark:border-gray-600">
                <input type="hidden" id="enrollment_year" name="enrollment_year">
                <input type="hidden" id="enrollment_month" name="enrollment_month">
                <input type="hidden" id="enrollment_day" name="enrollment_day">
            </div>

            <div class="col-span-2 text-center">
                <input type="submit" value="üéØ Predict Learning Strategy"
                    class="mt-6 bg-indigo-600 hover:bg-indigo-700 dark:bg-indigo-500 dark:hover:bg-indigo-600 text-white py-3 px-6 rounded-2xl font-semibold text-lg shadow-md transition transform hover:scale-105">
            </div>
        </form>
    </div>
</body>
</html>

"""

app = Flask(__name__)

@app.route('/')
def home():
    return render_template_string(html)
@app.route('/predict', methods=['POST'])
def predict():
    try:
        # Step 1: Collect and preprocess form data
        age = float(request.form['age'])
        study_hours = float(request.form['study_hours'])
        online_courses = int(request.form['online_courses'])
        assignment_rate = float(request.form['assignment_rate'])
        exam_score = float(request.form['exam_score'])
        attendance = float(request.form['attendance'])
        social_media = float(request.form['social_media'])
        sleep_hours = float(request.form['sleep_hours'])
        language_proficiency = float(request.form['language_proficiency'])

        final_grade = request.form['final_grade']
        gender = request.form['gender']
        tech_use = request.form['tech_use']
        stress_level = request.form['stress_level']
        learning_style = request.form['learning_style']
        participation = request.form['participation']
        hearing_issue = request.form['hearing_issue']
        vision_issue = request.form['vision_issue']
        focus_issue = request.form['focus_issue']

        #  enrollment date
        enrollment_date_str = request.form['enrollment_date']
        enrollment_date = datetime.strptime(enrollment_date_str, "%Y-%m-%d")
        enrollment_year = enrollment_date.year
        enrollment_month = enrollment_date.month
        enrollment_day = enrollment_date.day

        # Step 2: Encode categorical variables
        gender_encoded = 1 if gender.lower() == 'male' else 0
        tech_use_encoded = {'low': 0, 'medium': 1, 'high': 2}.get(tech_use.lower(), 0)
        stress_level_encoded = {'low': 0, 'medium': 1, 'high': 2}.get(stress_level.lower(), 0)
        learning_style_encoded = {'visual': 1, 'kinesthetic': 2, 'auditory': 3}.get(learning_style.lower(), 0)
        participation_encoded = {'low': 0, 'medium': 1, 'high': 2}.get(participation.lower(), 0)
        hearing_issue_encoded = {'yes': 0, 'no': 1}.get(hearing_issue.lower(), 0)
        vision_issue_encoded = {'yes': 0, 'no': 1}.get(vision_issue.lower(), 0)
        focus_issue_encoded = {'yes': 0, 'no': 1}.get(focus_issue.lower(), 0)
        final_grade_encoded = {'a': 0, 'b': 1, 'c': 2, 'd': 3}.get(final_grade.lower(), 0)

        # Derived Features

        study_hours_per_week_to_age_ratio = study_hours / age if age else 0
        exam_attendance_rate = (attendance / 100) * exam_score
        study_hours_to_exam_score = study_hours / exam_score if exam_score else 0
        study_hours_to_attendance = study_hours / attendance if attendance else 0
        weighted_exam_score = exam_score * (assignment_rate / 100)
        learning_style_effect = study_hours * online_courses


        #  feature list for prediction
        features = [
            age,
            study_hours,
            online_courses,
            assignment_rate,
            exam_score,
            attendance,
            social_media,
            sleep_hours,
            language_proficiency,
            final_grade_encoded,
            gender_encoded,
            tech_use_encoded,
            stress_level_encoded,
            learning_style_encoded,
            participation_encoded,
            hearing_issue_encoded,
            vision_issue_encoded,
            focus_issue_encoded,
            enrollment_year,
            enrollment_month,
            enrollment_day,
            study_hours_per_week_to_age_ratio,
            exam_attendance_rate,
            study_hours_to_exam_score,
            study_hours_to_attendance,
            weighted_exam_score,
            learning_style_effect
        ]

        #  prediction
        prediction = calibrated_model.predict([features])[0]
        print("Features:", features)
        print("Prediction:", prediction)
        if hasattr(calibrated_model, "predict_proba"):
            print("Prediction probabilities:", calibrated_model.predict_proba([features]))

        strategy_mapping = {'VIDEO': 0, 'AUDIO': 1, 'TEXT': 2}
        predicted_strategy_name = list(strategy_mapping.keys())[list(strategy_mapping.values()).index(prediction)]

        # Provide advice per strategy
        strategy_advice = {
            "VIDEO": {
                "name": "Video-Based Learning",
                "advice": [
                    "Use platforms like YouTube or Coursera.",
                    "Replay complex parts to reinforce understanding.",
                    "Use video transcripts to follow along."
                ]
            },
            "AUDIO": {
                "name": "Audio-Based Learning",
                "advice": [
                    "Try audiobooks or educational podcasts.",
                    "Record lectures and replay during commutes.",
                    "Practice active listening and note-taking."
                ]
            },
            "TEXT": {
                "name": "Text-Based Learning",
                "advice": [
                    "Read articles, books, and summaries.",
                    "Take notes and highlight key concepts.",
                    "Use flashcards and written practice."
                ]
            }
        }

        strategy = strategy_advice.get(predicted_strategy_name, {})
        strategy_name = strategy.get("name", "Unknown")
        advice_list = strategy.get("advice", [])
        advice_items = "".join([f"<li>{tip}</li>" for tip in advice_list])

        #  HTML response
        return f"""
        <!DOCTYPE html>
        <html lang="en" class="dark">
        <head>
            <meta charset="UTF-8">
            <title>Prediction Result</title>
            <script src="https://cdn.tailwindcss.com"></script>
            <script>
                tailwind.config = {{ darkMode: 'class' }};
            </script>
        </head>
        <body class="bg-gradient-to-br from-gray-100 to-gray-300 dark:from-gray-900 dark:to-gray-800 text-gray-800 dark:text-white min-h-screen flex items-center justify-center p-6">
            <div class="bg-white dark:bg-gray-900 shadow-2xl rounded-3xl p-10 max-w-3xl w-full space-y-8 transition-all duration-300">
                <div class="text-center">
                    <h1 class="text-4xl font-bold text-green-600 dark:text-green-400">üéØ Prediction Complete!</h1>
                    <p class="text-lg mt-2">The recommended <span class="font-semibold text-blue-600 dark:text-blue-400">learning strategy</span> is:</p>
                    <p class="text-3xl font-bold text-blue-700 dark:text-blue-300 mt-4 animate-pulse">
                        {strategy_name}
                    </p>
                </div>
                <div class="bg-gray-100 dark:bg-gray-800 rounded-xl p-6 shadow-inner">
                    <h2 class="text-xl font-semibold mb-4 text-gray-700 dark:text-gray-200">üìö Recommended Tips:</h2>
                    <ul class="list-disc list-inside space-y-2 text-gray-700 dark:text-gray-300 text-md">
                        {advice_items}
                    </ul>
                </div>
                <div class="text-center">
                    <a href="/" class="inline-flex items-center px-6 py-3 bg-blue-600 text-white rounded-xl hover:bg-blue-700 transition">
                        üîÅ Predict Another
                    </a>
                </div>
            </div>
        </body>
        </html>
        """

    except Exception as e:
        return f"<h2 class='text-red-500'>Error: {str(e)}</h2>", 400# Start ngrok to provide public URL
public_url = ngrok.connect(5000)
print(f"üîó Public URL: {public_url}")

if __name__ == '__main__':
    app.run()



